# TransformerScratch
Created a vanilla Transformer and a Universal Transformer from scratch .

Implemented the following

Word Embeddings
Positional Embeddings
Encoder
Decoder
Multihead Self Attention mechanism
Adam optimizer with warmup


Trained both the models on Cornell movie dialogues dataset

